--
-- PostgreSQL database dump
--

SET statement_timeout = 0;
SET lock_timeout = 0;
SET client_encoding = 'UTF8';
SET standard_conforming_strings = off;
SET check_function_bodies = false;
SET client_min_messages = warning;
SET escape_string_warning = off;

--
-- Name: plpgsql; Type: EXTENSION; Schema: -; Owner: 
--

CREATE EXTENSION IF NOT EXISTS plpgsql WITH SCHEMA pg_catalog;


--
-- Name: EXTENSION plpgsql; Type: COMMENT; Schema: -; Owner: 
--

COMMENT ON EXTENSION plpgsql IS 'PL/pgSQL procedural language';


SET search_path = public, pg_catalog;

SET default_tablespace = '';

SET default_with_oids = false;

--
-- Name: schema_migrations; Type: TABLE; Schema: public; Owner: hwttebiccfumlp; Tablespace: 
--

CREATE TABLE schema_migrations (
    version character varying(255) NOT NULL
);


ALTER TABLE public.schema_migrations OWNER TO hwttebiccfumlp;

--
-- Name: tutorials; Type: TABLE; Schema: public; Owner: hwttebiccfumlp; Tablespace: 
--

CREATE TABLE tutorials (
    id integer NOT NULL,
    name character varying(255),
    content text,
    created_at timestamp without time zone NOT NULL,
    updated_at timestamp without time zone NOT NULL
);


ALTER TABLE public.tutorials OWNER TO hwttebiccfumlp;

--
-- Name: tutorials_id_seq; Type: SEQUENCE; Schema: public; Owner: hwttebiccfumlp
--

CREATE SEQUENCE tutorials_id_seq
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;


ALTER TABLE public.tutorials_id_seq OWNER TO hwttebiccfumlp;

--
-- Name: tutorials_id_seq; Type: SEQUENCE OWNED BY; Schema: public; Owner: hwttebiccfumlp
--

ALTER SEQUENCE tutorials_id_seq OWNED BY tutorials.id;


--
-- Name: users; Type: TABLE; Schema: public; Owner: hwttebiccfumlp; Tablespace: 
--

CREATE TABLE users (
    id integer NOT NULL,
    email character varying(255) DEFAULT ''::character varying NOT NULL,
    encrypted_password character varying(255) DEFAULT ''::character varying NOT NULL,
    reset_password_token character varying(255),
    reset_password_sent_at timestamp without time zone,
    remember_created_at timestamp without time zone,
    sign_in_count integer DEFAULT 0,
    current_sign_in_at timestamp without time zone,
    last_sign_in_at timestamp without time zone,
    current_sign_in_ip character varying(255),
    last_sign_in_ip character varying(255),
    created_at timestamp without time zone NOT NULL,
    updated_at timestamp without time zone NOT NULL
);


ALTER TABLE public.users OWNER TO hwttebiccfumlp;

--
-- Name: users_id_seq; Type: SEQUENCE; Schema: public; Owner: hwttebiccfumlp
--

CREATE SEQUENCE users_id_seq
    START WITH 1
    INCREMENT BY 1
    NO MINVALUE
    NO MAXVALUE
    CACHE 1;


ALTER TABLE public.users_id_seq OWNER TO hwttebiccfumlp;

--
-- Name: users_id_seq; Type: SEQUENCE OWNED BY; Schema: public; Owner: hwttebiccfumlp
--

ALTER SEQUENCE users_id_seq OWNED BY users.id;


--
-- Name: id; Type: DEFAULT; Schema: public; Owner: hwttebiccfumlp
--

ALTER TABLE ONLY tutorials ALTER COLUMN id SET DEFAULT nextval('tutorials_id_seq'::regclass);


--
-- Name: id; Type: DEFAULT; Schema: public; Owner: hwttebiccfumlp
--

ALTER TABLE ONLY users ALTER COLUMN id SET DEFAULT nextval('users_id_seq'::regclass);


--
-- Data for Name: schema_migrations; Type: TABLE DATA; Schema: public; Owner: hwttebiccfumlp
--

COPY schema_migrations (version) FROM stdin;
20130228031550
20130303210658
\.


--
-- Data for Name: tutorials; Type: TABLE DATA; Schema: public; Owner: hwttebiccfumlp
--

COPY tutorials (id, name, content, created_at, updated_at) FROM stdin;
3	02 - Build this site 2 (devise)	Now that we have a content engine we need a user login system.\r\n<h3>Install Devise</h3>\r\n<ol>\r\n  <li>First we need to add devise to our Gemfile</li>\r\n    <h4>Gemfile</h4>\r\n    <code lang="ruby">gem 'devise'</code>\r\n  <li>Once that is done we update bundler</li>\r\n    <pre>bundle</pre>\r\n    This updates the Gemfile.lock<br><br>\r\n  <li>Now that we have devise we can start setting it up. This will create the initializer</li>\r\n    <pre>rails g devise:install</pre>\r\n    This creates:<br>config/initializers/devise.rb and<br>config/locales/devise.en.yml<br><br>\r\n    <li>Finally we can create the User model</li>\r\n    <pre>rails g devise User</pre>\r\n    <pre>rake db:migrate</pre>\r\n</ol>\r\n\r\n<h3>Asset Pipeline Workaround</h3>\r\nAlso I had to add this line to keep things working smoothly with Heroku:\r\n<h4>config/application.rb</h4>\r\n<code lang="ruby">\r\nmodule Joshcasts\r\n  class Application < Rails::Application\r\n...\r\n    # Fix heroku issue\r\n    config.assets.initialize_on_precompile = false\r\n...\r\n  end\r\nend\r\n</code>\r\n\r\nNow login and create the first user for yourself. Ahhh uid=1 my favorite!	2013-03-03 20:53:51.055236	2013-03-03 21:55:08.574451
1	01 - Build this site 1 (coderay)	First we need to generate the model\r\n\r\n<pre>rails g model tutorial name:string content:text</pre>\r\n\r\nWe'll use coderay for making tutorials pretty\r\n\r\n<code lang="ruby">\r\ngem 'coderay'\r\n</code>\r\n\r\n<h3>Routes</h3>\r\n<code lang="ruby">\r\nMysite::Application.routes.draw do\r\n  resources :tutorials\r\n  root :to => 'tutorials#index'\r\nend\r\n</code>\r\n\r\n<h3>Model</h3>\r\n[Edit] We want sorting on this so we have some consistency\r\n<code lang="ruby">\r\nclass Tutorial < ActiveRecord::Base\r\n  attr_accessible :content, :name\r\n\r\n  default_scope order('name')\r\nend\r\n</code>\r\n\r\n<h3>Controller</h3>\r\n<code lang="ruby">\r\nclass TutorialsController < ApplicationController\r\n  def index\r\n    @tutorials = Tutorial.all\r\n  end\r\n\r\n  def show\r\n    @tutorial = Tutorial.find(params[:id])\r\n  end\r\n\r\n  def new\r\n    @tutorial = Tutorial.new\r\n  end\r\n\r\n  def edit\r\n    @tutorial = Tutorial.find(params[:id])\r\n  end\r\n\r\n  def create\r\n    @tutorial = Tutorial.new(params[:tutorial])\r\n    if @tutorial.save\r\n      redirect_to @tutorial, notice: 'Tutorial was successfully created.'\r\n    else\r\n      render action: "new"\r\n    end\r\n  end\r\n\r\n  def update\r\n    @tutorial = Tutorial.find(params[:id])\r\n\r\n    if @tutorial.update_attributes(params[:tutorial])\r\n      redirect_to @tutorial, notice: 'Tutorial was successfully updated.'\r\n    else\r\n      render action: "edit"\r\n    end\r\n  end\r\n\r\n  def destroy\r\n    @tutorial = Tutorial.find(params[:id])\r\n    @tutorial.destroy\r\n\r\n    redirect_to tutorials_url\r\n  end\r\nend\r\n</code>\r\n\r\nYou'll want to modify the layout to wrap everything in a div\r\n\r\n<code>\r\n<div class="container">\r\n  <%= yield %>\r\n</div>\r\n</code>\r\n\r\nAlso for style points install twitter bootstrap\r\n	2013-02-28 03:24:01.131238	2013-03-03 21:49:48.627975
2	04 - Basic Gem	The simplest gem is just a Gemfile and gemspec. This example paves the way for clean reusable code.\r\n\r\n<h4>Gemfile</h4>\r\n<code lang="ruby">\r\nsource 'https://rubygems.org'\r\ngemspec\r\n</code>\r\n\r\n<h4>app.gemspec</h4>\r\n<code lang="ruby">\r\nGem::Specification.new do |gem|\r\n  gem.name    = "app"\r\n  gem.version = "0.0.1"\r\nend\r\n</code>	2013-03-03 20:49:30.504485	2013-03-03 21:36:38.155985
7	07 - Message Queue (Basic Sample)	<p>This configuration allow multiple publishers and multiple subscribers. Each message sent from the publishers will be received by only one of the subscribers.</p>\r\n\r\n<p>\r\nHere we have a simple publisher subscriber model. The publisher sends the first argument into the queue. The subscriber listens for messages and prints them out. In this example either side can be restarted and the flow will resume. Also the queue is self creating so this example should work "out of the box".\r\n</p>\r\n\r\n<h3>Basic Connection</h3>\r\n<p>This creates a connection to the message queue and starts it. Then it creates a queue or opens the existing one.</p>\r\n<code lang="ruby">\r\nrequire 'bunny'\r\n\r\nbunny = Bunny.new(:host => 'localhost', :port => 5673)\r\nbunny.start\r\n\r\nqueue = bunny.queue(:bunny_relay)\r\n</code>\r\n\r\n<h3>Sender</h3>\r\n<p>This will send the first argument as a message to the queue. Notice the key must match the queue name.</p>\r\n<code lang="ruby">\r\nexchange = bunny.exchange('')\r\nexchange.publish(ARGV[0], :key => :bunny_relay)\r\n</code>\r\n\r\n<h3>Receiver</h3>\r\n<p>This will begin reading messages from the queue</p>\r\n<code lang="ruby">\r\nqueue.subscribe do |message|\r\n  puts message\r\nend\r\n</code>	2013-03-08 02:02:13.744975	2013-03-10 10:27:44.501701
28	26 - Autoconf (Part 1: Required Macros)	<h2>Part 1: Required Macros</h2>\r\n<div class="well">\r\n<h3>AC_INIT</h3>\r\n<code>\r\nAC_INIT (package, version, [bug-report], [tarname], [url])\r\n</code>\r\n<p>\r\nAC_INIT should be called before anything else and specifies the package information.\r\n</p>\r\n<ul>\r\n  <li><b>package:</b> The package name</li>\r\n  <li><b>version:</b> The package version</li>\r\n  <li><b>bug-report:</b> Email to send bug reports to</li>\r\n  <li><b>url:</b> Project URL</li>\r\n</ul>\r\n<h4>Basic Example</h4>\r\n<code lang="bash">\r\nAC_INIT(myapp, 1.0)\r\n</code>\r\n<br>\r\n</div>\r\n\r\n<div class="well">\r\n<h3>AC_OUTPUT</h3>\r\n<code>\r\nAC_OUTPUT\r\n</code>\r\n<p>\r\nAC_OUTPUT creates config.status which is responsible for creating makefile and other files that use the configuration.\r\n</p>\r\n<h4>Basic Example</h4>\r\n<code lang="bash">\r\nAC_INIT(myapp, 1.0)\r\nAC_OUTPUT\r\n</code>\r\n<br>\r\n</div>\r\n\r\n<h2>Part 2: Versioning Macros</h2>\r\n<div class="well">\r\n<h3>AC_PREREQ</h3>\r\n<code>\r\nAC_PREREQ (version)\r\n</code>\r\n<p>\r\nAC_PREREQ defines the minimum version of autoconf that should be used to compile configure.ac.\r\n</p>\r\n<ul>\r\n  <li><b>version:</b> The minimum required autoconf version\r\n</ul>\r\n<h4>Basic Example</h4>\r\n<code lang="bash">\r\nAC_INIT(myapp, 1.0)\r\nAC_PREREQ(2.69)\r\nAC_OUTPUT\r\n</code>\r\n<br>\r\n</div>	2013-08-18 19:11:07.465435	2013-08-18 19:55:15.284534
5	05 - Simple application config template	<code lang="ruby">\r\nmodule App\r\n  class Config < Hash\r\n    def method_missing(name, *args)\r\n      super unless has_key? name\r\n      self[name]\r\n    end\r\n  end\r\nend\r\n</code>\r\n\r\n<code lang="ruby">\r\nmodule App\r\n  @config = Config.new\r\n\r\n  def self.default_config\r\n    @default_config ||= Config.new\r\n  end\r\n\r\n  def self.configure(opts = {})\r\n    default_config.merge @config.merge!(opts)\r\n  end\r\n\r\n  def self.config\r\n    default_config.merge @config\r\n  end\r\nend\r\n</code>	2013-03-06 06:19:46.017058	2013-03-06 06:29:56.042125
31	29 - How I make rails projects (part 1)	<h2>Creation</h2>\r\nThere are a few things to know when creating a new rails project that can save you time. The first one is picking a database during project creation to avoid having to edit several files immediately after the project is made.\r\n\r\n<code lang="bash">\r\nrails new myproject -d mysql\r\n</code>\r\n\r\n<h2>Testing</h2>\r\nAlso before creating any additional models/controllers etc it's good to setup your test suite so that rails will automatically create those resources from the beginning to avoid having to go back and manually add them yourself.\r\n\r\n<h3>Gemfile</h3>\r\n<code lang="ruby">\r\ngroup :test, :development do\r\n  gem 'rspec-rails'\r\nend\r\n</code>\r\n\r\n<code lang="bash">\r\nrails g rspec:install\r\n</code>\r\n\r\n<h2>Configuration</h2>\r\n\r\n<h3>Gemfile</h3>\r\n<code lang="ruby">\r\ngem 'figaro'\r\n</code>\r\n\r\n<code lang="bash">\r\nrails g figaro:install\r\n</code>\r\n\r\nNow we can put our environment specific setting in the config/application.yml file.\r\n\r\n<code lang="bash">\r\nrails g scaffold aws::region name:string\r\nrails g scaffold aws::elastic_ip region_id:integer instance_id:integer public_ip:string domain:string\r\nrails g scaffold aws::image region_id:integer image_id:string name:string description:string\r\nrails g scaffold aws::vpc region_id:integer vpc_id:string name:string cidr_block:string\r\nrails g scaffold aws::subnet vpc_id:integer subnet_id:string name:string cidr_block:string\r\nrails g scaffold aws::instance region_id:integer subnet_id:integer instance_id:string name:string image_id:string instance_type:string private_ip_address:string ip_address:string status:string\r\n</code>	2013-11-17 03:47:16.89448	2013-11-17 06:04:09.752859
4	03 - Build this site 3 (security)	Now that we have devise and a user model it's time to lock things down.\r\n\r\n<h4>app/models/user.rb</h4>\r\nRemove the :registerable from the "devise" statement. Mine looks as follows:\r\n<code lang="ruby">\r\nmodule Joshcasts\r\n  class Application < Rails::Application\r\n...\r\n    devise :database_authenticatable, #:registerable,\r\n         :recoverable, :rememberable, :trackable, :validatable\r\n...\r\n  end\r\nend\r\n</code>\r\n<h4>app/controller/tutorials.rb</h4>\r\nAdd authenticate_user! before filter to actions that require user authentication.\r\n<code lang="ruby">\r\nclass TutorialsController < ApplicationController\r\n  before_filter :authenticate_user!, :except => [:show, :index]\r\n...\r\nend\r\n</code>\r\n\r\nYou now have the only user account and only users can create/update/delete tutorials. Also creating new accounts is now disabled. Congratulations it's safe now :)	2013-03-03 21:36:25.368383	2013-03-10 03:19:53.348253
6	06 - Simple application config template (Part 2)	<code lang="ruby">\r\nrequire 'app'\r\n\r\ndescribe App do\r\n  it { should respond_to :config }\r\n  it { should respond_to :configure }\r\n  it { should respond_to :default_config }\r\n\r\n  describe :configure do\r\n    before do\r\n      @config = App.configure(:foo => :bar)\r\n    end\r\n\r\n    it "should return copies" do\r\n      @config.should_not equal(App.config)\r\n    end\r\n\r\n    it "should reflect changes" do\r\n      @config[:foo].should eql(:bar)\r\n    end\r\n\r\n    it "should modify config" do\r\n      App.config[:foo].should eql(:bar)\r\n    end\r\n\r\n    it "should include defaults" do\r\n      default_keys = App.default_config.keys\r\n      @config.keys.should include(*default_keys)\r\n    end\r\n  end\r\n\r\n  describe :config do\r\n    before do\r\n      @config = App.config\r\n    end\r\n\r\n    it "should return copies" do\r\n      @config.should_not equal(App.config)\r\n    end\r\n\r\n    it "should include defaults" do\r\n      default_keys = App.default_config.keys\r\n      @config.keys.should include(*default_keys)\r\n    end\r\n  end\r\nend\r\n</code>\r\n\r\n<code lang="ruby">\r\ndescribe App::Config do\r\n  before do\r\n    @config = App::Config.new.merge(:foo => :bar)\r\n  end\r\n\r\n  it { should be_kind_of(Hash) }\r\n\r\n  it "should expose keys as methods" do\r\n    @config.foo.should eql(:bar)\r\n  end\r\n\r\n  it "should still trigger method missing exceptions" do\r\n    lambda { @config.still_missing }.should raise_error(NoMethodError)\r\n  end\r\nend\r\n</code>	2013-03-06 06:25:54.301748	2013-03-10 10:27:31.410942
33	31 - Ubuntu NAT Server	<h3>Setup iptables</h3>\r\n\r\n<h4>One time</h4>\r\n\r\n<code lang="bash">\r\niptables -P FORWARD ACCEPT\r\niptables --table nat -A POSTROUTING -o eth0 -j MASQUERADE\r\n</code>\r\n\r\n<h4>Permanent</h4>\r\nTo do this permanently create a networking startup script <b>/etc/network/if-up.d/nat_server</b>\r\n\r\n<code lang="bash">\r\n#!/bin/bash\r\n/sbin/iptables -P FORWARD ACCEPT\r\n/sbin/iptables --table nat -A POSTROUTING -o eth0 -j MASQUERADE\r\n</code>\r\n\r\n<h3>Setup sysctl</h3>\r\n\r\n<h4>One time</h4>\r\n\r\n<code lang="bash">\r\nsysctl -w net.ipv4.ip_forward=1\r\n</code>\r\n\r\n<h4>Permanent</h4>\r\nTo do this permenantly create a sysctl partial config <b>/etc/sysctl.d/10-nat-server.conf</b>\r\n\r\n<code lang="bash">\r\nnet.ipv4.ip_forward = 1\r\n</code>	2014-01-02 15:44:10.354452	2014-01-02 18:24:38.448274
35	32 - Fancy bash	<code lang="bash">\r\n#!/bin/bash\r\nprint_status() {\r\n  echo -ne " * $1\\033[80G"\r\n}\r\n\r\nprint_success() {\r\n  echo -ne "\\033[74G[\\033[32m OK \\033[00m]\\n"\r\n}\r\n\r\nprint_fail() {\r\n  echo -ne "\\033[74G[\\033[31m NG \\033[00m]\\n"\r\n}\r\n\r\nsome_task() {\r\n  echo "output line 1"\r\n  echo "output line 2"\r\n  echo "output line 3"\r\n}\r\n\r\nprint_status Testing Stuff\r\noutput=$(some_task)\r\nprint_success\r\necho "$output"\r\n\r\nprint_status Testing Other Stuff\r\noutput=$(some_task)\r\nprint_fail\r\necho "$output"\r\n</code>	2014-01-29 02:50:23.849443	2014-01-29 02:50:23.849443
34	33 - Linux	<code lang="bash">\r\nfdisk -l\r\nfdisk /dev/sda\r\n</code>\r\n\r\n<code lang="bash">\r\ngrub-install --boot-directory /mnt/lfs/boot /dev/sda\r\n</code>	2014-01-20 16:18:29.934574	2014-03-05 23:23:53.599622
36	34 - Hacking git	<h2>Hooks</h2>\r\n\r\n<h3>update</h3>\r\n\r\nrefname sha1-old sha1-new\r\n\r\n<p>Remote repo still has sha1-old at head</p>\r\n\r\n<h3>post-update</h3>\r\n\r\nrefname\r\n\r\n<p>Remote repo now has latest code</p>\r\n\r\n<h2>Sample script</h2>\r\n\r\n<code lang="bash">\r\n#!/bin/sh\r\necho "\\b\\b\\b\\b\\b\\b\\b\\b=== STARTING BUILD ===\\033[0;31m" >&2\r\ncd /home/josh/Desktop/gitplay/builds/sandbox || exit\r\nunset GIT_DIR\r\n\r\nGIT_PULL_LOG=`git pull origin master 2>&1`\r\nbundle --deployment --clean\r\necho "\\033[m\\b\\b\\b\\b\\b\\b\\b\\b=== DONE ===" >&2\r\n</code>	2014-03-05 23:24:29.81453	2014-03-05 23:58:57.143713
32	30 - Rapid Infrastructure Development (part 1)	It's almost 1AM... let's make an infrastructure :)\r\n\r\n<p>Things we'll need</p>\r\n<ol>\r\n  <li>Amazon Web Services account</li>\r\n  <li>Github account (preferably with private repos)</li>\r\n  <li>Imagination</li>\r\n</ol>\r\n\r\n<h2>Getting started</h2>\r\nI've decided to leverage (buzz word alert) rails to automate the process.\r\n\r\n<h3>Let's create a new rails application:</h3>\r\n\r\n<code lang="bash">rails new rid -d mysql</code>\r\n\r\nEdit the Gemfile and add the figaro gem.\r\n\r\n<code lang="bash">rails g figaro:install</code>\r\n\r\nAdd your AWS credentials to the config/application.yml and create a config/initializer/aws.rb file.\r\n\r\n<code>\r\nAWS.config(access_key_id: Figaro.env.aws_access_key_id, secret_access_key: Figaro.env.aws_secret_access_key)\r\n</code>\r\n\r\n\r\n<h3>Now we need to create something to track the AWS regions</h3>\r\n\r\n<code lang="bash">\r\nrails g scaffold region name:string\r\n</code>\r\n\r\nLets keep things simple since these don't change much and create a rake task to populate them. Create lib/tasks/aws.rake with the following content\r\n\r\n<code lang="ruby">\r\ndesc "Populate AWS regions"\r\ntask :populate_regions => [:environment] do\r\n  AWS::EC2.new.regions.each do |region|\r\n    Region.find_or_create_by(name: region.name)\r\n  end\r\nend\r\n</code>\r\n\r\nWe'll need a private key in each region to create and log into instances. Let's create a model for that now:\r\n\r\n<code lang="bash">\r\nrails g scaffold key_pair region_id:integer name:string private_key:text\r\n</code>\r\n\r\nThis of coarse will belong to a region so go ahead and update the model for that. Now the fun part we'll create a before create callback to actually create the key for us so edit app/models/key_pair.rb and add this callback and method:\r\n\r\n<code lang="ruby">\r\n  before_create :create_aws_key_pair\r\n\r\n  def create_aws_key_pair\r\n    begin\r\n      aws_region = AWS::EC2.new.regions[self.region.name]\r\n      aws_key_pair = aws_region.key_pairs.create(name)\r\n      self.private_key = aws_key_pair.private_key\r\n    rescue Exception => e\r\n      errors[:exception] = e.message\r\n      false\r\n    end\r\n  end\r\n</code>\r\n\r\nOkay we should be able to make a new instance now so lets setup that model\r\n\r\n<code lang="bash">\r\nrails g model instance name:string region_id:integer key_pair_id:integer image_id:string\r\n</code>\r\n\r\n<h3>What we ended up with</h3>\r\n<code lang="ruby">\r\nclass KeyPair < ActiveRecord::Base\r\n  belongs_to :region\r\n  before_create :create_aws_key_pair\r\n  before_destroy :destroy_aws_key_pair\r\n\r\n  def destroy_aws_key_pair\r\n    begin\r\n      aws_region = AWS::EC2.new.regions[self.region.name]\r\n      aws_region.key_pairs[name].delete\r\n    rescue Exception => e\r\n      errors[:exception] = e.message\r\n      false\r\n    end\r\n  end\r\n\r\n  def create_aws_key_pair\r\n    begin\r\n      aws_region = AWS::EC2.new.regions[self.region.name]\r\n      aws_key_pair = aws_region.key_pairs.create(name)\r\n      self.private_key = aws_key_pair.private_key\r\n    rescue Exception => e\r\n      errors[:exception] = e.message\r\n      false\r\n    end\r\n  end\r\nend\r\n</code>\r\n\r\n<code lang="ruby">\r\nclass Instance < ActiveRecord::Base\r\n  belongs_to :region\r\n  belongs_to :key_pair\r\n  before_create :create_aws_instance\r\n  before_destroy :destroy_aws_instance\r\n\r\n  def destroy_aws_instance\r\n    begin\r\n      aws_region = AWS::EC2.new.regions[self.region.name]\r\n      aws_region.instances[instance_id].delete\r\n    rescue Exception => e\r\n      errors[:exception] = e.message\r\n      false\r\n    end\r\n  end\r\n\r\n  def create_aws_instance\r\n    begin\r\n      aws_region = AWS::EC2.new.regions[self.region.name]\r\n      aws_instance = aws_region.instances.create(\r\n        :image_id => image_id,\r\n        :key_name => key_pair.name\r\n      )\r\n      self.instance_id = aws_instance.id\r\n    rescue Exception => e\r\n      errors[:exception] = e.message\r\n      false\r\n    end\r\n  end\r\nend\r\n</code>	2013-11-24 05:47:43.98146	2013-11-24 06:57:56.157898
10	03 - Build this site 4 (bash syntax)	<code lang="diff">\r\ndiff --git a/Gemfile b/Gemfile\r\nindex dc05d66..cb6d2f7 100644\r\n--- a/Gemfile\r\n+++ b/Gemfile\r\n@@ -7,6 +7,7 @@ gem 'rails', '3.2.12'\r\n \r\n gem 'pg'\r\n gem 'coderay'\r\n+gem 'coderay_bash'\r\n gem 'devise'\r\n \r\n \r\ndiff --git a/Gemfile.lock b/Gemfile.lock\r\nindex 24cff72..5cd78d4 100644\r\n--- a/Gemfile.lock\r\n+++ b/Gemfile.lock\r\n@@ -32,6 +32,8 @@ GEM\r\n     bcrypt-ruby (3.0.1)\r\n     builder (3.0.4)\r\n     coderay (1.0.9)\r\n+    coderay_bash (1.0.4)\r\n+      coderay (>= 1.0)\r\n     coffee-rails (3.2.2)\r\n       coffee-script (>= 2.2.0)\r\n       railties (~> 3.2.0)\r\n@@ -115,6 +117,7 @@ PLATFORMS\r\n \r\n DEPENDENCIES\r\n   coderay\r\n+  coderay_bash\r\n   coffee-rails (~> 3.2.1)\r\n   devise\r\n   jquery-rails\r\n</code>	2013-03-10 01:43:00.313777	2013-03-10 01:56:38.094007
18	16 - Collectd (Packaging)	<code>\r\nsudo apt-get install librabbitmq-dev\r\n\r\n</code>\r\n\r\n<code lang="bash">\r\nsudo apt-get build-dep collectd\r\napt-get source collectd\r\nwget http://collectd.org/files/collectd-5.2.1.tar.gz\r\ntar -zxvf collectd-5.2.1.tar.gz\r\ncp -r collectd-4.10.1/debian collectd-5.2.1\r\ncd collectd-5.2.1\r\n</code>\r\n\r\nRemove the old patches\r\n<code>\r\nrm debian/patches/*\r\ntouch debian/patches/00list\r\n</code>\r\n\r\n<code>\r\ncollectd (5.2.1-jaja1) precise; urgency=low\r\n\r\n  * Update to lastest stable version.\r\n\r\n -- Joshua Bussdieker <jbussdieker@gmail.com>  Sun, 10 Mar 2013 03:35:18 -0800\r\n</code>	2013-03-10 10:40:42.242077	2013-03-10 11:17:53.010935
12	11 - Icinga (Putting it all together)	<code>\r\nsudo useradd icinga\r\n\r\nsudo apt-get install libdbd-mysql\r\nsudo apt-get install libgd2-xpm\r\nsudo apt-get install apache2\r\n\r\nsudo vim /etc/init.d/icinga\r\nsudo vim /etc/apache2/conf.d/icinga.conf\r\nsudo vim /etc/init.d/ido2db\r\n\r\nsudo service ido2db start\r\nsudo service icinga start\r\nsudo service apache2 reload\r\n</code>	2013-03-10 05:16:28.565497	2013-03-10 10:26:47.268808
11	10 - Icinga (Installing Nagios Plugins)	<h3>1. Prerequisites</h3>\r\n<code lang="bash">\r\nsudo apt-get install build-essential libssl-dev libmysqlclient-dev\r\n</code>\r\n\r\n<h3>2. Download Source</h3>\r\n<code lang="bash">\r\nwget http://sourceforge.net/projects/nagiosplug/files/nagiosplug/1.4.16/nagios-plugins-1.4.16.tar.gz\r\ntar -zxvf nagios-plugins-1.4.16.tar.gz\r\ncd nagios-plugins-1.4.16\r\n</code>\r\n\r\n<h3>2. Compile and Install</h3>\r\n<code lang="bash">\r\n./configure --prefix=/usr/local/icinga --with-cgiurl=/icinga/cgi-bin --with-nagios-user=icinga --with-nagios-group=icinga\r\nmake\r\nsudo make install\r\n</code>	2013-03-10 04:01:59.11186	2013-03-10 10:26:55.368421
19	17 - Creating an APT Server	Pick a location to host your apt packages. For this example I'll use /mnt/apt.\r\n\r\n<code lang="bash">\r\nmkdir /mnt/apt\r\ncd /mnt/apt\r\nmkdir -p dists/precise/main/binary-amd64\r\nmkdir -p dists/precise/main/binary-i386\r\nmkdir -p dists/precise/main/source\r\necho "dpkg-scanpackages dists/precise/main/binary-amd64 /dev/null | \r\n  gzip -9c > dists/precise/main/binary-amd64/Packages.gz\r\ndpkg-scanpackages dists/precise/main/binary-i386 /dev/null | \r\n  gzip -9c > dists/precise/main/binary-i386/Packages.gz\r\ndpkg-scansources dists/precise/main/source /dev/null | \r\n  gzip -9c > dists/precise/main/source/Sources.gz" > build.sh\r\nchmod +x build.sh\r\n./build.sh\r\nls */*/*/*\r\n</code>\r\n\r\n<h4>/etc/apache2/conf.d/apt-server.conf</h4>\r\n<code>\r\nAlias /repos "/mnt/apt"\r\n<Directory "/mnt/apt">\r\n   Options None\r\n   AllowOverride All\r\n   Order allow,deny\r\n   Allow from all\r\n</Directory>\r\n</code>\r\n\r\n<h4>/etc/apt/sources.list.d/apt-server.list</h4>\r\n<code>\r\ndeb http://localhost/repos/ precise main\r\ndeb-src http://localhost/repos/ precise main\r\n</code>	2013-03-11 07:20:03.622492	2013-03-11 07:28:57.249277
17	15 - Graphite (Putting it all together)	<code lang="bash">\r\nsudo dpkg -i python-whisper_0.9.10-jaja1_all.deb \r\nsudo dpkg -i python-carbon_0.9.10-jaja1_all.deb \r\nsudo dpkg -i python-graphite-web_0.9.10-jaja1_all.deb \r\n\r\n# Create the initial database\r\nsudo python /opt/graphite/webapp/graphite/manage.py syncdb\r\n\r\n# Start the web server\r\nsudo /opt/graphite/bin/run-graphite-devel-server.py /opt/graphite &\r\n\r\n# Copy default settings\r\nsudo cp /opt/graphite/conf/carbon.conf.example /opt/graphite/conf/carbon.conf\r\nsudo cp /opt/graphite/conf/storage-schemas.conf.example /opt/graphite/conf/storage-schemas.conf\r\n\r\n# Start the data collector\r\nsudo /opt/graphite/bin/carbon-cache.py --debug start &\r\n\r\n# Log a metric\r\necho "test 1 `date +%s`" | nc localhost 2003\r\n</code>	2013-03-10 09:36:56.669765	2013-03-10 10:26:10.657174
20	18 - Better Packaging of Whisper/Carbon/Graphite	You'll need the following installed:\r\n<ul>\r\n  <li>python-stdeb</li>\r\n  <li>devscripts</li>\r\n</ul>\r\n\r\n<h3>Whisper</h3>\r\n<code lang="bash">\r\nmkdir whisper\r\ncd whisper\r\nwget https://launchpad.net/graphite/0.9/0.9.10/+download/whisper-0.9.10.tar.gz\r\npy2dsc -m 'Joshua Bussdieker <josh.bussdieker@moovweb.com>' whisper-0.9.10.tar.gz\r\ncd deb_dist/whisper-0.9.10\r\ndebuild\r\n</code>\r\n\r\n<h3>Carbon</h3>\r\n<code lang="bash">\r\nmkdir carbon\r\ncd carbon\r\nwget https://launchpad.net/graphite/0.9/0.9.10/+download/carbon-0.9.10.tar.gz\r\npy2dsc -m 'Joshua Bussdieker <josh.bussdieker@moovweb.com>' carbon-0.9.10.tar.gz\r\ncd deb_dist/carbon-0.9.10\r\ndebuild\r\n</code>\r\n\r\n<code lang="diff">\r\n< Depends: ${misc:Depends}, ${python:Depends}\r\n> Depends: ${misc:Depends}, ${python:Depends}, python-whisper (>= 0.9.10)\r\n</code>\r\n\r\n<h3>Graphite-Web</h3>\r\n<code lang="bash">\r\nmkdir graphite-web\r\ncd graphite-web\r\nwget https://launchpad.net/graphite/0.9/0.9.10/+download/graphite-web-0.9.10.tar.gz\r\npy2dsc -m 'Joshua Bussdieker <josh.bussdieker@moovweb.com>' graphite-web-0.9.10.tar.gz\r\ncd deb_dist/graphite-web-0.9.10\r\ndebuild\r\n</code>\r\n\r\n<code lang="diff">\r\n< Depends: ${misc:Depends}, ${python:Depends}\r\n> Depends: ${misc:Depends}, ${python:Depends}, python-django (>= 1.3.1), python-django-tagging (>= 0.3.1)\r\n</code>	2013-03-11 07:32:47.705957	2013-05-15 16:43:42.260462
16	14 - Graphite (Packaging Graphite-Web)	<h3>1. Download and extract the source</h3>\r\n<code lang="bash">\r\nwget https://launchpad.net/graphite/0.9/0.9.10/+download/graphite-web-0.9.10.tar.gz\r\ntar -zxvf graphite-web-0.9.10.tar.gz\r\n</code>\r\n\r\n<h3>2. Setup debian package config</h3>\r\n<code lang="bash">\r\ncd graphite-web-0.9.10\r\nmkdir debian\r\necho 7 > debian/compat\r\n</code>\r\n\r\n<h4>debian/rules</h4>\r\n<div class="alert">Be sure to mark this file executable</div>\r\n<code>\r\n#!/usr/bin/make -f\r\n\r\n%:\r\n        dh $@\r\n</code>\r\n\r\n<h4>debian/changelog</h4>\r\n<code>\r\npython-graphite-web (0.9.10-jaja1) unstable; urgency=low\r\n\r\n  * Initial release\r\n\r\n -- Joshua Bussdieker <jbussdieker@gmail.com>  Sun, 10 Mar 2013 01:24:08 -0800\r\n</code>\r\n\r\n<h4>debian/control</h4>\r\n<code>\r\nSource: python-graphite-web\r\nSection: python\r\nPriority: optional\r\nMaintainer: Joshua Bussdieker <jbussdieker@gmail.com>\r\nBuild-Depends: debhelper (>= 7.0.50), python-support (>= 0.6.4), python (>= 2.5)\r\nXS-Python-Version: >= 2.5\r\nStandards-Version: 3.9.2\r\nHomepage: https://launchpad.net/graphite\r\nVcs-Svn: svn://svn.debian.org/python-modules/packages/python-graphite-web/trunk/\r\nVcs-Browser: http://svn.debian.org/viewsvn/python-modules/packages/python-graphite-web/trunk/\r\n\r\nPackage: python-graphite-web\r\nArchitecture: all\r\nDepends: python-whisper, python-django, python-django-tagging, python-cairo, ${misc:Depends}, ${python:Depends}\r\nSuggests: python-carbon\r\nDescription: Graphical interface to whisper data.\r\n</code>\r\n\r\n<h3>3. Build the package</h3>\r\n<code lang="bash">\r\nfakeroot debian/rules binary\r\n</code>	2013-03-10 08:37:13.551849	2013-03-10 10:26:17.446482
15	13 - Graphite (Packaging Carbon)	<h3>1. Download and extract the source</h3>\r\n<code lang="bash">\r\nwget https://launchpad.net/graphite/0.9/0.9.10/+download/carbon-0.9.10.tar.gz\r\ntar -zxvf carbon-0.9.10.tar.gz\r\n</code>\r\n\r\n<h3>2. Setup debian package config</h3>\r\n<code lang="bash">\r\ncd carbon-0.9.10\r\nmkdir debian\r\necho 7 > debian/compat\r\n</code>\r\n\r\n<h4>debian/rules</h4>\r\n<div class="alert">Be sure to mark this file executable</div>\r\n<code>\r\n#!/usr/bin/make -f\r\n\r\n%:\r\n        dh $@\r\n</code>\r\n\r\n<h4>debian/changelog</h4>\r\n<code>\r\npython-carbon (0.9.10-jaja1) unstable; urgency=low\r\n\r\n  * Initial release\r\n\r\n -- Joshua Bussdieker <jbussdieker@gmail.com>  Sat, 09 Mar 2013 23:53:31 -0800\r\n</code>\r\n\r\n<h4>debian/control</h4>\r\n<code>\r\nSource: python-carbon\r\nSection: python\r\nPriority: optional\r\nMaintainer: Joshua Bussdieker <jbussdieker@gmail.com>\r\nBuild-Depends: debhelper (>= 7.0.50), python-support (>= 0.6.4), python (>= 2.5)\r\nXS-Python-Version: >= 2.5\r\nStandards-Version: 3.9.2\r\nHomepage: https://launchpad.net/graphite\r\nVcs-Svn: svn://svn.debian.org/python-modules/packages/python-carbon/trunk/\r\nVcs-Browser: http://svn.debian.org/viewsvn/python-modules/packages/python-carbon/trunk/\r\n\r\nPackage: python-carbon\r\nArchitecture: all\r\nDepends: python-whisper, ${misc:Depends}, ${python:Depends}\r\nSuggests: python-graphite\r\nDescription: Aggregation tool for whisper.\r\n</code>\r\n\r\n<h3>3. Build the package</h3>\r\n<code lang="bash">\r\nfakeroot debian/rules binary\r\n</code>	2013-03-10 07:46:46.444282	2013-03-10 10:26:25.341569
14	12 - Graphite (Packaging Whisper)	First we need to get the latest source from apt and from upstream. Then copy the debian folder.\r\n<code>\r\nsudo apt-get build-dep python-whisper\r\napt-get source python-whisper\r\nwget https://launchpad.net/graphite/0.9/0.9.10/+download/whisper-0.9.10.tar.gz\r\ntar -zxvf whisper-0.9.10.tar.gz\r\ncp -r python-whisper-0.9.8/debian whisper-0.9.10\r\n</code>\r\n\r\n<h4>debian/rules</h4>\r\nThere are overrides for the binary names to make them more friendly so lets keep those.\r\n<code lang="diff">\r\n\t[ -f debian/python-whisper/usr/bin/whisper-update ] || mv debian/python-whisper/usr/bin/whisper-update.py debian/python-whisper/usr/bin/whisper-update\r\n+\t[ -f debian/python-whisper/usr/bin/whisper-dump ] || mv debian/python-whisper/usr/bin/whisper-dump.py debian/python-whisper/usr/bin/whisper-dump\r\n+\t[ -f debian/python-whisper/usr/bin/whisper-merge ] || mv debian/python-whisper/usr/bin/whisper-merge.py debian/python-whisper/usr/bin/whisper-merge\r\n+\t[ -f debian/python-whisper/usr/bin/whisper-set-aggregation-method ] || mv debian/python-whisper/usr/bin/whisper-set-aggregation-method.py debian/python-whisper/usr/bin/whisper-set-aggregation-method\r\n\tdh_install\r\n</code>\r\n\r\n<h4>debian/changelog</h4>\r\nWe need to add an entry to the changelog to reflect the updates.\r\n<code lang="diff">\r\n+python-whisper (0.9.10-jaja1) unstable; urgency=low\r\n+\r\n+  * Update to latest stable source.\r\n+\r\n+ -- Joshua Bussdieker <jbussdieker@gmail.com>  Sat, 09 Mar 2013 23:03:00 -0800\r\n+\r\npython-whisper (0.9.8-1) unstable; urgency=low\r\n\r\n  * New upstream version.\r\n  * Bump Standards-Version.\r\n\r\n -- Elliot Murphy <elliot@ubuntu.com>  Wed, 27 Apr 2011 09:39:51 -0400\r\n\r\npython-whisper (0.9.6-1) unstable; urgency=low\r\n\r\n  * Initial release (Closes: #563765)\r\n\r\n -- Elliot Murphy <elliot@ubuntu.com>  Mon, 07 Jun 2010 16:40:44 -0500\r\n</code>\r\n\r\nFinally we rebuild the package\r\n<code>\r\ncd whisper-0.9.10\r\nfakeroot debian/rules binary\r\n</code>	2013-03-10 06:21:56.120343	2013-03-10 10:26:37.413517
9	09 - Icinga (Installing Icinga w/ IDO)	<h3>1. Prerequisites</h3>\r\n<code lang="bash">\r\nsudo apt-get install build-essential libgd2-xpm-dev libdbi-dev libdbd-mysql mysql-server apache2\r\n</code>\r\n\r\n<h3>2. Download Source</h3>\r\n<code lang="bash">\r\nwget http://sourceforge.net/projects/icinga/files/icinga/1.8.4/icinga-1.8.4.tar.gz\r\ntar -zxvf icinga-1.8.4.tar.gz\r\ncd icinga-1.8.4\r\n</code>\r\n\r\n<h3>3. MySQL Setup</h3>\r\n<code lang="bash">\r\nsudo mysql -e "CREATE DATABASE icinga"\r\nsudo mysql -e "GRANT USAGE ON icinga.* TO 'icinga'@'localhost'\r\n   IDENTIFIED BY 'icinga'\r\n   WITH MAX_QUERIES_PER_HOUR 0\r\n   MAX_CONNECTIONS_PER_HOUR 0\r\n   MAX_UPDATES_PER_HOUR 0;"\r\nsudo mysql -e "GRANT SELECT, INSERT, UPDATE, DELETE, DROP, CREATE VIEW, INDEX, EXECUTE\r\n   ON icinga.* TO 'icinga'@'localhost';"\r\nsudo mysql -e "FLUSH PRIVILEGES;"\r\nsudo mysql icinga < module/idoutils/db/mysql/mysql.sql\r\n</code>\r\n\r\n<h3>4. Setup User</h3>\r\n<code lang="bash">\r\nsudo adduser icinga\r\n</code>\r\n\r\n<h3>5. Compile and Install</h3>\r\n<code lang="bash">\r\n./configure --enable-idoutils --with-command-group=www-data\r\nmake all\r\nsudo make install\r\nsudo make install-config\r\nsudo make install-init\r\nsudo make install-commandmode\r\nsudo make install-idoutils\r\n</code>\r\n\r\n<h3>6. Setup Configuration</h3>\r\n<code lang="bash">\r\nsudo htpasswd -c /usr/local/icinga/etc/htpasswd.users icingaadmin\r\nsudo cp /usr/local/icinga/etc/ido2db.cfg-sample /usr/local/icinga/etc/ido2db.cfg\r\nsudo cp /usr/local/icinga/etc/idomod.cfg-sample /usr/local/icinga/etc/idomod.cfg\r\nsudo cp /usr/local/icinga/etc/modules/idoutils.cfg-sample /usr/local/icinga/etc/modules/idoutils.cfg\r\n</code>	2013-03-09 23:47:10.749134	2013-03-10 10:27:04.991337
8	08 - JSON Hash	<code lang="ruby">\r\nclass BaseHash < Hash\r\n  def initialize(data = {})\r\n    super.merge!(data)\r\n  end\r\n\r\n  def method_missing(name, *args)\r\n    super unless has_key? name.to_s\r\n    self[name.to_s]\r\n  end\r\n\r\n  def self.new(data)\r\n    case data\r\n      when String\r\n        super(JSON.parse(data))\r\n      when Hash\r\n        super(data)\r\n      else\r\n        raise("Invalid data format")\r\n    end\r\n  end\r\nend\r\n</code>	2013-03-08 02:58:20.418625	2013-03-10 10:27:55.386386
25	23 - Package redis like a boss	Start the package\r\n<code lang="bash">\r\nmkdir redis_package && cd redis_package\r\nwget http://redis.googlecode.com/files/redis-2.6.14.tar.gz\r\nmkdir redis-2.6.14 && cd redis-2.6.14\r\ngit init\r\ngit-import-orig ../redis-2.6.14.tar.gz --pristine-tar --no-interactive\r\ndh_make -s\r\n</code>\r\n\r\nClean up a bit\r\n<code lang="bash">\r\ncd debian\r\nrm -f *.ex *.EX README.Debian README.source info docs\r\n</code>\r\n\r\nUse upstream copyright and default config\r\n<code lang="bash">\r\ncp COPYING debian/copyright\r\ncp redis.conf debian/redis.conf\r\n</code>\r\n\r\nFix the default config\r\n<code lang="diff">\r\ndiff --git a/debian/redis.conf b/debian/redis.conf\r\nindex 9b90646..c2ea146 100644\r\n--- a/debian/redis.conf\r\n+++ b/debian/redis.conf\r\n@@ -14,11 +14,11 @@\r\n \r\n # By default Redis does not run as a daemon. Use 'yes' if you need it.\r\n # Note that Redis will write a pid file in /var/run/redis.pid when daemonized.\r\n-daemonize no\r\n+daemonize yes\r\n \r\n # When running daemonized, Redis writes a pid file in /var/run/redis.pid by\r\n # default. You can specify a custom pid file location here.\r\n-pidfile /var/run/redis.pid\r\n+pidfile /var/run/redis/redis-server.pid\r\n \r\n # Accept connections on the specified port, default is 6379.\r\n # If port 0 is specified Redis will not listen on a TCP socket.\r\n@@ -27,13 +27,13 @@ port 6379\r\n # If you want you can bind a single interface, if the bind option is not\r\n # specified all the interfaces will listen for incoming connections.\r\n #\r\n-# bind 127.0.0.1\r\n+bind 127.0.0.1\r\n \r\n # Specify the path for the unix socket that will be used to listen for\r\n # incoming connections. There is no default, so Redis will not listen\r\n # on a unix socket when not specified.\r\n #\r\n-# unixsocket /tmp/redis.sock\r\n+# unixsocket /var/run/redis/redis.sock\r\n # unixsocketperm 755\r\n \r\n # Close the connection after a client is idle for N seconds (0 to disable)\r\n@@ -66,7 +66,7 @@ loglevel notice\r\n # Specify the log file name. Also 'stdout' can be used to force\r\n # Redis to log on the standard output. Note that if you use standard\r\n # output for logging but daemonize, logs will be sent to /dev/null\r\n-logfile stdout\r\n+logfile /var/log/redis/redis-server.log\r\n\r\n # To enable logging to the system logger, just set 'syslog-enabled' to yes,\r\n # and optionally update the other syslog parameters to suit your needs.\r\n@@ -150,7 +150,7 @@ dbfilename dump.rdb\r\n # The Append Only File will also be created inside this directory.\r\n # \r\n # Note that you must specify a directory here, not a file name.\r\n-dir ./\r\n+dir /var/lib/redis\r\n \r\n ################################# REPLICATION #################################\r\n\r\n</code>\r\n\r\nFix the control file\r\n<code lang="diff">\r\ndiff --git a/debian/control b/debian/control\r\nindex f7ec4d9..351171d 100644\r\n--- a/debian/control\r\n+++ b/debian/control\r\n@@ -1,15 +1,19 @@\r\n Source: redis\r\n-Section: unknown\r\n-Priority: extra\r\n+Section: database\r\n+Priority: optional\r\n Maintainer: Joshua Bussdieker <josh.bussdieker@moovweb.com>\r\n Build-Depends: debhelper (>= 8.0.0)\r\n-Standards-Version: 3.9.2\r\n-Homepage: <insert the upstream URL, if relevant>\r\n+Standards-Version: 3.9.3\r\n+Homepage: http://redis.io/\r\n #Vcs-Git: git://git.debian.org/collab-maint/redis.git\r\n #Vcs-Browser: http://git.debian.org/?p=collab-maint/redis.git;a=summary\r\n \r\n-Package: redis\r\n+Package: redis-server\r\n Architecture: any\r\n Depends: ${shlibs:Depends}, ${misc:Depends}\r\n-Description: <insert up to 60 chars description>\r\n- <insert long description, indented with spaces>\r\n+Description: Persistent key-value database with network interface\r\n+ Redis is a key-value database in a similar vein to memcache but the dataset\r\n+ is non-volatile. Redis additionally provides native support for atomically\r\n+ manipulating and querying data structures such as lists and sets.\r\n+ .\r\n+ The dataset is stored entirely in memory and periodically flushed to disk.\r\n</code>\r\n\r\nFix the changelog\r\n<code lang="diff">\r\ndiff --git a/debian/changelog b/debian/changelog\r\nindex 724bdd7..cc64c6d 100644\r\n--- a/debian/changelog\r\n+++ b/debian/changelog\r\n@@ -1,5 +1,5 @@\r\n-redis (2.6.14-1) unstable; urgency=low\r\n+redis (2.6.14-moov1) unstable; urgency=low\r\n \r\n-  * Initial release (Closes: #nnnn)  <nnnn is the bug number of your ITP>\r\n+  * Initial release\r\n \r\n  -- Joshua Bussdieker <josh.bussdieker@moovweb.com>  Thu, 20 Jun 2013 14:01:10 -0700\r\n</code>\r\n\r\nFix the rules\r\n<code lang="diff">\r\ndiff --git a/debian/rules b/debian/rules\r\nindex b760bee..1425e92 100755\r\n--- a/debian/rules\r\n+++ b/debian/rules\r\n@@ -11,3 +11,11 @@\r\n \r\n %:\r\n        dh $@ \r\n+\r\n+override_dh_auto_test:\r\n+\r\n+override_dh_auto_install:\r\n+\r\n+clean:\r\n+       dh $@\r\n+       rm -f src/release.h\r\n+       rm -f deps/jemalloc/bin/jemalloc.sh\r\n</code>\r\n\r\nBuild it\r\n<code lang="bash">\r\ngit-buildpackage --git-ignore-new\r\n</code>	2013-06-20 20:43:57.132155	2013-06-20 21:39:30.260615
22	20 - L2TP/IPsec VPN	<div class="well">\r\n<h2>Setup IPsec</h2>\r\n<p>\r\nThe first thing you will need to setup is IPsec. The package bundled with Ubuntu 12.04 and 12.10 doesn't work so well with NAT so we'll need to build a newer version from source.\r\n</p>\r\n<code>\r\nsudo apt-get build-dep openswan\r\ngit clone git://github.com/xelerance/Openswan.git\r\ncd Openswan\r\ngit checkout v2.6.39dr3\r\nsudo make programs install\r\n</code>\r\n\r\n<h3>/etc/ipsec.conf</h3>\r\nThis file setups up the global and connection specific settings related to IPsec. There are several settings that must match the L2TP configuration but if you stick with this configuration everything should go smoothly.\r\n<code>\r\nversion\t2.0\r\n\r\nconfig setup\r\n  plutodebug=none\r\n  strictcrlpolicy=no\r\n  nat_traversal=yes\r\n  interfaces=%defaultroute\r\n  virtual_private=%v4:10.0.0.0/8,%v4:192.168.0.0/16,%v4:172.16.0.0/12,%v6:fd00::/8,%v6:fe80::/10\r\n  oe=off\r\n  protostack=netkey\r\n\r\nconn %default\r\n  keyingtries=3\r\n  pfs=no\r\n  rekey=yes\r\n  type=transport\r\n  left=%defaultroute\r\n  leftprotoport=17/1701\r\n  rightprotoport=17/1701\r\n\r\nconn acme\r\n  authby=secret\r\n  right=8.67.53.9\r\n  left=%defaultroute\r\n  rightid=""\r\n  auto=start\r\n</code>\r\n\r\n<h3>/etc/ipsec.secrets</h3>\r\nThis is where you will want to enter the private shared key. This is usually the same for everyone.\r\n<code>\r\n%any %any : PSK "acme-vpc-private-shared-key"\r\n</code>\r\n</div>\r\n\r\n<div class="well">\r\n<h2>Setup L2TP</h2>\r\n<code>\r\nsudo apt-get install xl2tpd\r\n</code>\r\n\r\n<h3>/etc/xl2tpd/xl2tpd.conf</h3>\r\nIn this configuration we specify the PPP settings as well as an additional config file with more detailed settings.\r\n<code>\r\n[global]\r\nipsec saref = yes\r\n\r\n[lac acme]\r\nlns = 8.67.53.9\r\npppoptfile = /etc/ppp/acme.options.xl2tpd\r\nlength bit = no\r\nredial = no\r\n</code>\r\n\r\n\r\n<h3>/etc/ppp/acme.options.xl2tpd</h3>\r\nThis is where you specify the username and password that will be used to connect to the tunnel.\r\n<code>\r\nipcp-accept-local\r\nipcp-accept-remote\r\nidle 72000\r\nktune\r\nnoproxyarp\r\nasyncmap 0\r\nnoauth\r\ncrtscts\r\nlock\r\nhide-password\r\nmodem\r\nnoipx\r\nrefuse-eap\r\n#refuse-pap\r\nrefuse-chap\r\nrefuse-mschap\r\nrefuse-mschap-v2\r\nremotename ""\r\nname "john.doe@acme.com"\r\npassword "likeaboss2013"\r\n</code>\r\n</div>	2013-03-17 10:24:04.600795	2013-03-17 11:57:28.375956
21	19 - PBuilder	pbuild allows us to create clean distribution roots that we can login to and test package dependencies. One we've created the base we can login, make changes and logout. When we login next time the root will have been cleaned back to it's original state.\r\n\r\n<code lang="bash">\r\nsudo pbuilder --create --extrapackages puppet vim --distribution lucid --basetgz lucid.tgz\r\nsudo pbuilder --create --extrapackages puppet vim --distribution precise --basetgz precise.tgz\r\n</code>	2013-03-16 00:21:32.958756	2013-03-17 12:02:39.509387
23	21 - Cheap Linux Snapshots	While packaging software or even troubleshooting existing installs it's helpful to track changes to the file system before and after certain programs or scripts are run. This helps to get an idea of what group of files are associated with a specific sequence of events.\r\n\r\n<code lang="bash">\r\n#!/bin/bash\r\nif [[ "x$1" != "x" ]]; then\r\n\tFILENAME=$1\r\nelse\r\n\tFILENAME=tmp_file\r\nfi\r\n\r\nsudo find / > $FILENAME\r\ncat $FILENAME |\r\n\tgrep -v "/proc" |\r\n        grep -v "/home" |\r\n\tgrep -v "/var/tmp" | \r\n\tgrep -v "/etc/app" |\r\n\tgrep -v "/var/lib/puppet" > ${FILENAME}_clean\r\n</code>	2013-03-18 01:56:04.670672	2013-03-18 01:56:58.838143
24	22 - Troubleshoot LT2P/IPsec Connections	Getting back to a known good state can be time consuming but worth it when testing configurations. Assuming everything were working and connected the following commands are the "reverse" procedure.\r\n\r\n<code lang="bash">\r\nsudo xl2tpd-control disconnect [connection_name]\r\nsudo service xl2tpd stop\r\nsudo ipsec auto --down [connection_name]\r\nsudo service ipsec stop\r\nsudo ifdown eth0; sudo ifup eth0\r\n</code>\r\n\r\nAt this point we would be able to do the following to reestablish the connection:\r\n\r\n<code lang="bash">\r\nsudo service ipsec start\r\nsudo ipsec auto --up [connection_name]\r\nsudo service xl2tpd start\r\nsudo xl2tpd-control connect [connection_name]\r\n</code>\r\n\r\n<h2>Expected Results</h2>\r\n<h3>sudo service ipsec start</h3>\r\n<code>\r\n==> /var/log/syslog <==\r\nMar 18 05:22:46 ip-10-197-44-114 kernel: [722034.050762] NET: Registered protocol family 15\r\nMar 18 05:22:46 ip-10-197-44-114 ipsec_setup: Starting Openswan IPsec U2.6.39dr3/K3.2.0-36-virtual...\r\nMar 18 05:22:46 ip-10-197-44-114 ipsec_setup: Using NETKEY(XFRM) stack\r\nMar 18 05:22:46 ip-10-197-44-114 kernel: [722034.146636] Initializing XFRM netlink socket\r\n\r\n==> /var/log/auth.log <==\r\nMar 18 05:22:46 ip-10-197-44-114 ipsec__plutorun: Starting Pluto subsystem...\r\n\r\n==> /var/log/syslog <==\r\nMar 18 05:22:46 ip-10-197-44-114 ipsec_setup: ...Openswan IPsec started\r\nMar 18 05:22:46 ip-10-197-44-114 ipsec__plutorun: adjusting ipsec.d to /etc/ipsec.d\r\nMar 18 05:22:46 ip-10-197-44-114 pluto: adjusting ipsec.d to /etc/ipsec.d\r\n\r\n==> /var/log/auth.log <==\r\nMar 18 05:22:46 ip-10-197-44-114 pluto[4856]: Starting Pluto (Openswan Version 2.6.39dr3; Vendor ID OElNuAbqH[yp) pid:4856\r\nMar 18 05:22:46 ip-10-197-44-114 pluto[4856]: LEAK_DETECTIVE support [disabled]\r\nMar 18 05:22:46 ip-10-197-44-114 pluto[4856]: OCF support for IKE [disabled]\r\nMar 18 05:22:46 ip-10-197-44-114 pluto[4856]: SAref support [disabled]: Protocol not available\r\nMar 18 05:22:46 ip-10-197-44-114 pluto[4856]: SAbind support [disabled]: Protocol not available\r\nMar 18 05:22:46 ip-10-197-44-114 pluto[4856]: NSS support [disabled]\r\nMar 18 05:22:46 ip-10-197-44-114 pluto[4856]: HAVE_STATSD notification support not compiled in\r\nMar 18 05:22:46 ip-10-197-44-114 pluto[4856]: Setting NAT-Traversal port-4500 floating to on\r\nMar 18 05:22:46 ip-10-197-44-114 pluto[4856]:    port floating activation criteria nat_t=1/port_float=1\r\nMar 18 05:22:46 ip-10-197-44-114 pluto[4856]:    NAT-Traversal support  [enabled]\r\nMar 18 05:22:46 ip-10-197-44-114 pluto[4856]: using /dev/urandom as source of random entropy\r\nMar 18 05:22:46 ip-10-197-44-114 pluto[4856]: ike_alg_register_enc(): Activating OAKLEY_AES_CBC: Ok (ret=0)\r\nMar 18 05:22:46 ip-10-197-44-114 pluto[4856]: ike_alg_register_hash(): Activating OAKLEY_SHA2_512: Ok (ret=0)\r\nMar 18 05:22:46 ip-10-197-44-114 pluto[4856]: ike_alg_register_hash(): Activating OAKLEY_SHA2_256: Ok (ret=0)\r\nMar 18 05:22:46 ip-10-197-44-114 pluto[4856]: starting up 1 cryptographic helpers\r\nMar 18 05:22:46 ip-10-197-44-114 pluto[4856]: started helper pid=4857 (fd:6)\r\nMar 18 05:22:46 ip-10-197-44-114 pluto[4856]: Using Linux 2.6 IPsec interface code on 3.2.0-36-virtual (experimental code)\r\nMar 18 05:22:46 ip-10-197-44-114 pluto[4857]: using /dev/urandom as source of random entropy\r\nMar 18 05:22:46 ip-10-197-44-114 pluto[4856]: ike_alg_register_enc(): Activating aes_ccm_8: Ok (ret=0)\r\nMar 18 05:22:46 ip-10-197-44-114 pluto[4856]: ike_alg_add(): ERROR: algo_type '0', algo_id '0', Algorithm type already exists\r\nMar 18 05:22:46 ip-10-197-44-114 pluto[4856]: ike_alg_register_enc(): Activating aes_ccm_12: FAILED (ret=-17)\r\nMar 18 05:22:46 ip-10-197-44-114 pluto[4856]: ike_alg_add(): ERROR: algo_type '0', algo_id '0', Algorithm type already exists\r\nMar 18 05:22:46 ip-10-197-44-114 pluto[4856]: ike_alg_register_enc(): Activating aes_ccm_16: FAILED (ret=-17)\r\nMar 18 05:22:46 ip-10-197-44-114 pluto[4856]: ike_alg_add(): ERROR: algo_type '0', algo_id '0', Algorithm type already exists\r\nMar 18 05:22:46 ip-10-197-44-114 pluto[4856]: ike_alg_register_enc(): Activating aes_gcm_8: FAILED (ret=-17)\r\nMar 18 05:22:46 ip-10-197-44-114 pluto[4856]: ike_alg_add(): ERROR: algo_type '0', algo_id '0', Algorithm type already exists\r\nMar 18 05:22:46 ip-10-197-44-114 pluto[4856]: ike_alg_register_enc(): Activating aes_gcm_12: FAILED (ret=-17)\r\nMar 18 05:22:46 ip-10-197-44-114 pluto[4856]: ike_alg_add(): ERROR: algo_type '0', algo_id '0', Algorithm type already exists\r\nMar 18 05:22:46 ip-10-197-44-114 pluto[4856]: ike_alg_register_enc(): Activating aes_gcm_16: FAILED (ret=-17)\r\nMar 18 05:22:46 ip-10-197-44-114 pluto[4856]: added connection description "[connection_name]"\r\n\r\n==> /var/log/syslog <==\r\nMar 18 05:22:46 ip-10-197-44-114 ipsec__plutorun: 002 added connection description "[connection_name]"\r\n\r\n==> /var/log/auth.log <==\r\nMar 18 05:22:46 ip-10-197-44-114 pluto[4856]: listening for IKE messages\r\nMar 18 05:22:46 ip-10-197-44-114 pluto[4856]: adding interface eth0/eth0 10.197.44.114:500\r\nMar 18 05:22:46 ip-10-197-44-114 pluto[4856]: adding interface eth0/eth0 10.197.44.114:4500\r\nMar 18 05:22:46 ip-10-197-44-114 pluto[4856]: adding interface lo/lo 127.0.0.1:500\r\nMar 18 05:22:46 ip-10-197-44-114 pluto[4856]: adding interface lo/lo 127.0.0.1:4500\r\nMar 18 05:22:46 ip-10-197-44-114 pluto[4856]: adding interface lo/lo ::1:500\r\nMar 18 05:22:46 ip-10-197-44-114 pluto[4856]: loading secrets from "/etc/ipsec.secrets"\r\n</code>\r\n\r\n<h3>sudo ipsec auto --up [connection_name]</h3>\r\n<code>\r\n==> /var/log/auth.log <==\r\nMar 18 05:25:32 ip-10-197-44-114 pluto[4856]: "[connection_name]" #1: initiating Main Mode\r\nMar 18 05:25:32 ip-10-197-44-114 pluto[4856]: "[connection_name]" #1: received Vendor ID payload [RFC 3947] method set to=115 \r\nMar 18 05:25:32 ip-10-197-44-114 pluto[4856]: "[connection_name]" #1: received Vendor ID payload [Dead Peer Detection]\r\nMar 18 05:25:32 ip-10-197-44-114 pluto[4856]: "[connection_name]" #1: enabling possible NAT-traversal with method RFC 3947 (NAT-Traversal)\r\nMar 18 05:25:32 ip-10-197-44-114 pluto[4856]: "[connection_name]" #1: transition from state STATE_MAIN_I1 to state STATE_MAIN_I2\r\nMar 18 05:25:32 ip-10-197-44-114 pluto[4856]: "[connection_name]" #1: STATE_MAIN_I2: sent MI2, expecting MR2\r\nMar 18 05:25:32 ip-10-197-44-114 pluto[4856]: "[connection_name]" #1: NAT-Traversal: Result using draft-ietf-ipsec-nat-t-ike (MacOS X): i am NATed\r\nMar 18 05:25:32 ip-10-197-44-114 pluto[4856]: "[connection_name]" #1: transition from state STATE_MAIN_I2 to state STATE_MAIN_I3\r\nMar 18 05:25:32 ip-10-197-44-114 pluto[4856]: "[connection_name]" #1: STATE_MAIN_I3: sent MI3, expecting MR3\r\nMar 18 05:25:32 ip-10-197-44-114 pluto[4856]: "[connection_name]" #1: Main mode peer ID is ID_IPV4_ADDR: '[connection_ip]'\r\nMar 18 05:25:32 ip-10-197-44-114 pluto[4856]: "[connection_name]" #1: transition from state STATE_MAIN_I3 to state STATE_MAIN_I4\r\nMar 18 05:25:32 ip-10-197-44-114 pluto[4856]: "[connection_name]" #1: STATE_MAIN_I4: ISAKMP SA established {auth=OAKLEY_PRESHARED_KEY cipher=oakley_3des_cbc_192 prf=oakley_sha group=modp1024}\r\nMar 18 05:25:32 ip-10-197-44-114 pluto[4856]: "[connection_name]" #1: Dead Peer Detection (RFC 3706): enabled\r\nMar 18 05:25:32 ip-10-197-44-114 pluto[4856]: "[connection_name]" #2: initiating Quick Mode PSK+ENCRYPT+UP+IKEv2ALLOW+SAREFTRACK {using isakmp#1 msgid:47d256bc proposal=defaults pfsgroup=no-pfs}\r\nMar 18 05:25:32 ip-10-197-44-114 pluto[4856]: "[connection_name]" #2: NAT-Traversal: received 2 NAT-OA. ignored because peer is not NATed\r\nMar 18 05:25:32 ip-10-197-44-114 pluto[4856]: "[connection_name]" #2: Dead Peer Detection (RFC 3706): enabled\r\nMar 18 05:25:32 ip-10-197-44-114 pluto[4856]: "[connection_name]" #2: transition from state STATE_QUICK_I1 to state STATE_QUICK_I2\r\nMar 18 05:25:32 ip-10-197-44-114 pluto[4856]: "[connection_name]" #2: STATE_QUICK_I2: sent QI2, IPsec SA established transport mode {ESP=>0x02daf2fe <0xb8c68330 xfrm=3DES_0-HMAC_SHA1 NATOA=none NATD=none DPD=enabled}\r\n</code>\r\n\r\nAt this point you should have a working IPsec connection ready for L2TP.\r\n\r\n<h3>sudo service xl2tpd start</h3>\r\n<code>\r\n==> /var/log/syslog <==\r\nMar 18 05:29:09 ip-10-197-44-114 xl2tpd[4917]: Enabling IPsec SAref processing for L2TP transport mode SAs\r\nMar 18 05:29:09 ip-10-197-44-114 xl2tpd[4917]: IPsec SAref does not work with L2TP kernel mode yet, enabling forceuserspace=yes\r\nMar 18 05:29:09 ip-10-197-44-114 xl2tpd[4917]: setsockopt recvref[30]: Protocol not available\r\nMar 18 05:29:09 ip-10-197-44-114 xl2tpd[4917]: This binary does not support kernel L2TP.\r\nMar 18 05:29:09 ip-10-197-44-114 xl2tpd[4918]: xl2tpd version xl2tpd-1.3.1 started on ip-10-197-44-114 PID:4918\r\nMar 18 05:29:09 ip-10-197-44-114 xl2tpd[4918]: Written by Mark Spencer, Copyright (C) 1998, Adtran, Inc.\r\nMar 18 05:29:09 ip-10-197-44-114 xl2tpd[4918]: Forked by Scott Balmos and David Stipp, (C) 2001\r\nMar 18 05:29:09 ip-10-197-44-114 xl2tpd[4918]: Inherited by Jeff McAdams, (C) 2002\r\nMar 18 05:29:09 ip-10-197-44-114 xl2tpd[4918]: Forked again by Xelerance (www.xelerance.com) (C) 2006\r\nMar 18 05:29:09 ip-10-197-44-114 xl2tpd[4918]: Listening on IP address 0.0.0.0, port 1701\r\n</code>\r\n\r\n<h3>sudo xl2tpd-control connect [connection_name]</h3>\r\n<code>\r\n==> /var/log/syslog <==\r\nMar 18 05:31:49 ip-10-197-44-114 xl2tpd[4918]: Connecting to host [connection_ip], port 1701\r\nMar 18 05:31:49 ip-10-197-44-114 xl2tpd[4918]: Connection established to [connection_ip], 1701.  Local: 41374, Remote: 3962 (ref=0/0).\r\nMar 18 05:31:49 ip-10-197-44-114 xl2tpd[4918]: Calling on tunnel 41374\r\nMar 18 05:31:49 ip-10-197-44-114 xl2tpd[4918]: Call established with [connection_ip], Local: 40068, Remote: 64627, Serial: 1 (ref=0/0)\r\nMar 18 05:31:49 ip-10-197-44-114 xl2tpd[4918]: start_pppd: I'm running: \r\nMar 18 05:31:49 ip-10-197-44-114 xl2tpd[4918]: "/usr/sbin/pppd" \r\nMar 18 05:31:49 ip-10-197-44-114 xl2tpd[4918]: "passive" \r\nMar 18 05:31:49 ip-10-197-44-114 xl2tpd[4918]: "nodetach" \r\nMar 18 05:31:49 ip-10-197-44-114 xl2tpd[4918]: ":" \r\nMar 18 05:31:49 ip-10-197-44-114 xl2tpd[4918]: "file" \r\nMar 18 05:31:49 ip-10-197-44-114 xl2tpd[4918]: "/etc/ppp/[connection_name].options.xl2tpd" \r\nMar 18 05:31:49 ip-10-197-44-114 xl2tpd[4918]: "ipparam" \r\nMar 18 05:31:49 ip-10-197-44-114 xl2tpd[4918]: "[connection_ip]" \r\nMar 18 05:31:49 ip-10-197-44-114 xl2tpd[4918]: "/dev/pts/3" \r\nMar 18 05:31:49 ip-10-197-44-114 pppd[4921]: pppd 2.4.5 started by root, uid 0\r\nMar 18 05:31:49 ip-10-197-44-114 pppd[4921]: Using interface ppp0\r\nMar 18 05:31:49 ip-10-197-44-114 pppd[4921]: Connect: ppp0 <--> /dev/pts/3\r\nMar 18 05:31:50 ip-10-197-44-114 pppd[4921]: Remote message: Session started successfully\r\nMar 18 05:31:50 ip-10-197-44-114 pppd[4921]: PAP authentication succeeded\r\nMar 18 05:31:50 ip-10-197-44-114 pppd[4921]: local  IP address 192.168.213.206\r\nMar 18 05:31:50 ip-10-197-44-114 pppd[4921]: remote IP address 172.16.0.1\r\n</code>	2013-03-18 05:20:41.650423	2013-03-18 05:49:06.896679
29	27 - Autoconf (Part 2: Versioning Macros)	<h2>AC_PREREQ</h2>\r\n<p>\r\nAC_PREREQ defines the minimum version of autoconf that should be used to compile configure.ac.\r\n</p>\r\n<pre>\r\nAC_PREREQ (version)\r\n</pre>\r\n<h4>Basic Example</h4>\r\nThe most basic autoconf example specifying only package name and version and requiring autoconf version 2.69 or later.\r\n<code lang="bash">\r\nAC_INIT(myapp, 1.0)\r\nAC_PREREQ(2.69)\r\n</code>	2013-08-18 19:44:36.281857	2013-08-18 19:46:29.689512
26	24 - Package icinga like a boss	Start the package\r\n<code lang="bash">\r\nmkdir icinga_package && cd icinga_package\r\nwget http://sourceforge.net/projects/icinga/files/icinga/1.6.1/icinga-1.6.1.tar.gz\r\nmkdir icinga-1.6.1 && cd icinga-1.6.1\r\ngit init\r\ngit-import-orig ../icinga-1.6.1.tar.gz --pristine-tar --no-interactive\r\ndh_make -m\r\n</code>\r\n\r\nClean up a bit\r\n<code lang="bash">\r\ncd debian\r\nrm -f *.ex *.EX README.Debian README.source info docs\r\n</code>\r\n\r\nUse upstream copyright\r\n<code lang="bash">\r\ncp LICENSE debian/copyright\r\n</code>	2013-06-27 20:37:58.881241	2013-06-27 20:51:32.595721
30	28 - RPM Packaging (Collectd)	<p>This was tested on Centos 6.3. You can build it using\r\n<code>rpmbuild -bb collectd.spec</code>\r\n</p>\r\n\r\nFiles\r\n<ul>\r\n  <li><a href="#collectd.spec">collectd.spec</a></li>\r\n  <li><a href="#collectd.service">/etc/init.d/collectd</a></li>\r\n</ul>\r\n\r\n<a id="collectd.spec"></a>\r\n<div class="well">\r\n<h2>collectd.spec</h2>\r\n<code>\r\nName: collectd\r\nVersion: 5.4.0\r\nRelease: 1\r\nSummary: Statistics collection daemon for filling RRD files\r\nLicense: GPLv2\r\nGroup: System Environment/Daemons\r\nURL: http://collectd.org\r\n\r\nSource: http://collectd.org/files/%{name}-%{version}.tar.gz \r\nSource3: collectd.service\r\n\r\nBuildRequires: perl(ExtUtils::MakeMaker)\r\nBuildRequires: perl(ExtUtils::Embed)\r\nBuildRequires: python-devel\r\nBuildRequires: libgcrypt-devel\r\nBuildRequires: autoconf, automake\r\n\r\n%description\r\ncollectd is a small daemon written in C for performance.  It reads various\r\nsystem  statistics  and updates  RRD files,  creating  them if necessary.\r\nSince the daemon doesn't need to startup every time it wants to update the\r\nfiles it's very fast and easy on the system. Also, the statistics are very\r\nfine grained since the files are updated every 10 seconds.\r\n\r\n%package apache\r\nSummary:       Apache plugin for collectd\r\nGroup:         System Environment/Daemons\r\nRequires:      collectd = %{version}-%{release}\r\n%description apache\r\nThis plugin collects data provided by Apache's 'mod_status'.\r\n\r\n%package ascent\r\nSummary:       Ascent plugin for collectd\r\nGroup:         System Environment/Daemons\r\nRequires:      collectd = %{version}-%{release}\r\nBuildRequires: curl-devel\r\nBuildRequires: libxml2-devel\r\n%description ascent\r\nThis plugin collects data about an Ascent server,\r\na free server for the "World of Warcraft" game.\r\n\r\n%package bind\r\nSummary:       Bind plugin for collectd\r\nGroup:         System Environment/Daemons\r\nRequires:      collectd = %{version}-%{release}\r\nBuildRequires: curl-devel\r\nBuildRequires: libxml2-devel\r\n%description bind\r\nThis plugin retrieves statistics from the BIND dns server.\r\n\r\n%package curl\r\nSummary:       Curl plugin for collectd\r\nGroup:         System Environment/Daemons\r\nRequires:      collectd = %{version}-%{release}\r\nBuildRequires: curl-devel\r\n%description curl\r\nThis plugin reads webpages with curl\r\n\r\n%package curl_json\r\nSummary:       Curl JSON plugin for collectd\r\nGroup:         System Environment/Daemons\r\nRequires:      collectd = %{version}-%{release}\r\nBuildRequires: curl-devel\r\nBuildRequires: yajl-devel\r\n%description curl_json\r\nThis plugin retrieves JSON data via curl.\r\n\r\n%package curl_xml\r\nSummary:       Curl XML plugin for collectd\r\nGroup:         System Environment/Daemons\r\nRequires:      collectd = %{version}-%{release}\r\nBuildRequires: curl-devel\r\nBuildRequires: libxml2-devel\r\n%description curl_xml\r\nThis plugin retrieves XML data via curl.\r\n\r\n%package dbi\r\nSummary:       DBI plugin for collectd\r\nGroup:         System Environment/Daemons\r\nRequires:      collectd = %{version}-%{release}\r\nBuildRequires: libdbi-devel\r\n%description dbi\r\nThis plugin uses the dbi library to connect to various databases,\r\nexecute SQL statements and read back the results.\r\n\r\n%package dns\r\nSummary:       DNS traffic analysis plugin for collectd\r\nGroup:         System Environment/Daemons\r\nRequires:      collectd = %{version}-%{release}\r\nBuildRequires: libpcap-devel\r\n%description dns\r\nThis plugin collects DNS traffic data.\r\n\r\n%package email\r\nSummary:       Email plugin for collectd\r\nGroup:         System Environment/Daemons\r\nRequires:      collectd = %{version}-%{release}, spamassassin\r\n%description email\r\nThis plugin collects data provided by spamassassin.\r\n\r\n%package generic-jmx\r\nSummary:       Generic JMX plugin for collectd\r\nGroup:         System Environment/Daemons\r\nRequires:      collectd-java = %{version}-%{release}\r\n%description generic-jmx\r\nThis plugin collects data provided by JMX.\r\n\r\n%package gmond\r\nSummary:       Gmond plugin for collectd\r\nGroup:         System Environment/Daemons\r\nRequires:      collectd = %{version}-%{release}, spamassassin\r\nBuildRequires: ganglia-devel\r\n%description gmond\r\nThis plugin receives multicast traffic sent by gmond,\r\nthe statistics collection daemon of Ganglia.\r\n\r\n%package ipmi\r\nSummary:       IPMI plugin for collectd\r\nGroup:         System Environment/Daemons\r\nRequires:      collectd = %{version}-%{release}\r\nBuildRequires: OpenIPMI-devel\r\n%description ipmi\r\nThis plugin for collectd provides IPMI support.\r\n\r\n%package iptables\r\nSummary:       Iptables plugin for collectd\r\nGroup:         System Environment/Daemons\r\nRequires:      collectd = %{version}-%{release}\r\nBuildRequires: iptables-devel\r\n%description iptables\r\nThis plugin collects data from iptables counters.\r\n\r\n%package ipvs\r\nSummary:       IPVS plugin for collectd\r\nGroup:         System Environment/Daemons\r\nRequires:      collectd = %{version}-%{release}\r\n%description ipvs\r\nThis plugin collects data from IPVS.\r\n\r\n%package java\r\nSummary:       Java bindings for collectd\r\nGroup:         System Environment/Daemons\r\nRequires:      collectd = %{version}-%{release}\r\nBuildRequires: java-devel\r\nBuildRequires: jpackage-utils\r\n%description java\r\nThese are the Java bindings for collectd.\r\n\r\n%package lvm\r\nSummary:       LVM plugin for collectd\r\nGroup:         System Environment/Daemons\r\nRequires:      collectd = %{version}-%{release}\r\nBuildRequires: lvm2-devel\r\n%description lvm\r\nThis plugin collects information from lvm\r\n\r\n%if 0%{?fedora} <= 18\r\n%package memcachec\r\nSummary:       Memcachec plugin for collectd\r\nGroup:         System Environment/Daemons\r\nRequires:      collectd = %{version}-%{release}\r\nBuildRequires: libmemcached-devel\r\n%description memcachec\r\nThis plugin connects to a memcached server, queries one or more\r\ngiven pages and parses the returned data according to user specification.\r\n%endif\r\n\r\n%package mysql\r\nSummary:       MySQL plugin for collectd\r\nGroup:         System Environment/Daemons\r\nRequires:      collectd = %{version}-%{release}\r\nBuildRequires: mysql-devel\r\n%description mysql\r\nMySQL querying plugin. This plugin provides data of issued commands,\r\ncalled handlers and database traffic.\r\n\r\n%package netlink\r\nSummary:       Netlink plugin for collectd\r\nGroup:         System Environment/Daemons\r\nRequires:      collectd = %{version}-%{release}\r\nBuildRequires: iproute-static, libmnl-devel\r\n%description netlink\r\nThis plugin uses a netlink socket to query the Linux kernel\r\nabout statistics of various interface and routing aspects.\r\n\r\n%package nginx\r\nSummary:       Nginx plugin for collectd\r\nGroup:         System Environment/Daemons\r\nRequires:      collectd = %{version}-%{release}\r\n%description nginx\r\nThis plugin collects data provided by Nginx.\r\n\r\n%package notify_desktop\r\nSummary:       Notify desktop plugin for collectd\r\nGroup:         System Environment/Daemons\r\nRequires:      collectd = %{version}-%{release}\r\nBuildRequires: libnotify-devel\r\n%description notify_desktop\r\nThis plugin sends a desktop notification to a notification daemon,\r\nas defined in the Desktop Notification Specification.\r\n\r\n%package notify_email\r\nSummary:       Notify email plugin for collectd\r\nGroup:         System Environment/Daemons\r\nRequires:      collectd = %{version}-%{release}\r\nBuildRequires: libesmtp-devel\r\n%description notify_email\r\nThis plugin uses the ESMTP library to send\r\nnotifications to a configured email address.\r\n\r\n%package -n perl-Collectd\r\nSummary:       Perl bindings for collectd\r\nGroup:         System Environment/Daemons\r\nRequires:      collectd = %{version}-%{release}\r\nRequires: perl(:MODULE_COMPAT_%(eval "`%{__perl} -V:version`"; echo $version))\r\n%description -n perl-Collectd\r\nThis package contains the Perl bindings and plugin for collectd.\r\n\r\n%package postgresql\r\nSummary:       PostgreSQL plugin for collectd\r\nGroup:         System Environment/Daemons\r\nRequires:      collectd = %{version}-%{release}\r\nBuildRequires: postgresql-devel\r\n%description postgresql\r\nPostgreSQL querying plugin. This plugins provides data of issued commands,\r\ncalled handlers and database traffic.\r\n\r\n%package rrdtool\r\nSummary:       RRDTool plugin for collectd\r\nGroup:         System Environment/Daemons\r\nRequires:      collectd = %{version}-%{release}\r\nBuildRequires: rrdtool-devel\r\n%description rrdtool\r\nThis plugin for collectd provides rrdtool support.\r\n\r\n%ifnarch ppc ppc64 sparc sparc64\r\n%package sensors\r\nSummary:       Libsensors module for collectd\r\nGroup:         System Environment/Daemons\r\nRequires:      collectd = %{version}-%{release}, lm_sensors\r\nBuildRequires: lm_sensors-devel\r\n%description sensors\r\nThis plugin for collectd provides querying of sensors supported by\r\nlm_sensors.\r\n%endif\r\n\r\n%package snmp\r\nSummary:       SNMP module for collectd\r\nGroup:         System Environment/Daemons\r\nRequires:      collectd = %{version}-%{release}, net-snmp\r\nBuildRequires: net-snmp-devel\r\n%description snmp\r\nThis plugin for collectd provides querying of net-snmp.\r\n\r\n%ifnarch ppc ppc64 sparc sparc64\r\n%package virt\r\nSummary:       Libvirt plugin for collectd\r\nGroup:         System Environment/Daemons\r\nRequires:      collectd = %{version}-%{release}\r\nBuildRequires: libvirt-devel\r\nBuildRequires: libxml2-devel\r\n%description virt\r\nThis plugin collects information from virtualized guests.\r\n%endif\r\n\r\n%prep\r\n%setup -q\r\n\r\n%build\r\n%configure CFLAGS="%{optflags} -DLT_LAZY_OR_NOW='RTLD_LAZY|RTLD_GLOBAL'" \\\r\n    --enable-all-plugins \\\r\n    --disable-static \\\r\n    --disable-amqp \\\r\n    --disable-apple_sensors \\\r\n    --disable-aquaero \\\r\n    --disable-lpar \\\r\n    --disable-mic \\\r\n%if 0%{?fedora} >= 19\r\n    --disable-memcachec \\\r\n%endif\r\n    --disable-modbus \\\r\n    --disable-netapp \\\r\n    --disable-nut \\\r\n    --disable-onewire \\\r\n    --disable-oracle \\\r\n    --disable-pinba \\\r\n    --disable-ping \\\r\n    --disable-pf \\\r\n    --disable-redis \\\r\n    --disable-routeros \\\r\n    --disable-rrdcached \\\r\n%ifarch ppc ppc64 sparc sparc64\r\n    --disable-sensors \\\r\n%endif\r\n    --disable-sigrok \\\r\n    --disable-tape \\\r\n    --disable-tokyotyrant \\\r\n    --disable-varnish \\\r\n    --disable-write_mongodb \\\r\n    --disable-write_redis \\\r\n    --disable-write_riemann \\\r\n    --disable-xmms \\\r\n    --disable-zfs_arc \\\r\n    --with-libiptc \\\r\n    --with-java=%{java_home}/ \\\r\n    --with-python \\\r\n    --with-perl-bindings=INSTALLDIRS=vendor\r\n\r\n%{__make} %{?_smp_mflags}\r\n\r\n%install\r\n%{__rm} -rf contrib/SpamAssassin\r\n%{__make} install DESTDIR="%{buildroot}"\r\n\r\n%{__install} -Dp -m0755 %{SOURCE3} %{buildroot}%{_sysconfdir}/init.d/collectd\r\n\r\n# Remove Perl hidden .packlist files.\r\nfind %{buildroot} -name .packlist -exec rm {} \\;\r\n# Remove Perl temporary file perllocal.pod\r\nfind %{buildroot} -name perllocal.pod -exec rm {} \\;\r\n\r\n# Move the Perl examples to a separate directory.\r\nmkdir perl-examples\r\nfind contrib -name '*.p[lm]' -exec mv {} perl-examples/ \\;\r\n\r\nmkdir -p %{buildroot}%{_sysconfdir}/collectd\r\nmv %{buildroot}/%{_sysconfdir}/collectd.conf %{buildroot}%{_sysconfdir}/collectd\r\n# *.la files shouldn't be distributed.\r\nrm -f %{buildroot}/%{_libdir}/{collectd/,}*.la\r\n\r\n%files\r\n%config(noreplace) %{_sysconfdir}/collectd/collectd.conf\r\n%config(noreplace) %{_sysconfdir}/init.d/collectd\r\n%exclude %{_datadir}/collectd/postgresql_default.conf\r\n\r\n%{_bindir}/collectd-nagios\r\n%{_bindir}/collectdctl\r\n%{_bindir}/collectd-tg\r\n%{_sbindir}/collectd\r\n%{_sbindir}/collectdmon\r\n\r\n%dir %{_libdir}/collectd\r\n\r\n%{_libdir}/collectd/aggregation.so\r\n%{_libdir}/collectd/apcups.so\r\n%{_libdir}/collectd/battery.so\r\n%{_libdir}/collectd/cgroups.so\r\n%{_libdir}/collectd/conntrack.so\r\n%{_libdir}/collectd/contextswitch.so\r\n%{_libdir}/collectd/cpu.so\r\n%{_libdir}/collectd/cpufreq.so\r\n%{_libdir}/collectd/csv.so\r\n%{_libdir}/collectd/df.so\r\n%{_libdir}/collectd/disk.so\r\n%{_libdir}/collectd/entropy.so\r\n%{_libdir}/collectd/ethstat.so\r\n%{_libdir}/collectd/exec.so\r\n%{_libdir}/collectd/filecount.so\r\n%{_libdir}/collectd/fscache.so\r\n%{_libdir}/collectd/hddtemp.so\r\n%{_libdir}/collectd/interface.so\r\n%{_libdir}/collectd/irq.so\r\n%{_libdir}/collectd/load.so\r\n%{_libdir}/collectd/logfile.so\r\n%{_libdir}/collectd/madwifi.so\r\n%{_libdir}/collectd/match_empty_counter.so\r\n%{_libdir}/collectd/match_hashed.so\r\n%{_libdir}/collectd/match_regex.so\r\n%{_libdir}/collectd/match_timediff.so\r\n%{_libdir}/collectd/match_value.so\r\n%{_libdir}/collectd/mbmon.so\r\n%{_libdir}/collectd/md.so\r\n%{_libdir}/collectd/memcached.so\r\n%{_libdir}/collectd/memory.so\r\n%{_libdir}/collectd/multimeter.so\r\n%{_libdir}/collectd/network.so\r\n%{_libdir}/collectd/nfs.so\r\n%{_libdir}/collectd/ntpd.so\r\n%{_libdir}/collectd/numa.so\r\n%{_libdir}/collectd/olsrd.so\r\n%{_libdir}/collectd/openvpn.so\r\n%{_libdir}/collectd/powerdns.so\r\n%{_libdir}/collectd/processes.so\r\n%{_libdir}/collectd/protocols.so\r\n%{_libdir}/collectd/python.so\r\n%{_libdir}/collectd/serial.so\r\n%{_libdir}/collectd/statsd.so\r\n%{_libdir}/collectd/swap.so\r\n%{_libdir}/collectd/syslog.so\r\n%{_libdir}/collectd/table.so\r\n%{_libdir}/collectd/tail.so\r\n%{_libdir}/collectd/tail_csv.so\r\n%{_libdir}/collectd/target_notification.so\r\n%{_libdir}/collectd/target_replace.so\r\n%{_libdir}/collectd/target_scale.so\r\n%{_libdir}/collectd/target_set.so\r\n%{_libdir}/collectd/target_v5upgrade.so\r\n%{_libdir}/collectd/tcpconns.so\r\n%{_libdir}/collectd/teamspeak2.so\r\n%{_libdir}/collectd/ted.so\r\n%{_libdir}/collectd/thermal.so\r\n%{_libdir}/collectd/threshold.so\r\n%{_libdir}/collectd/unixsock.so\r\n%{_libdir}/collectd/uptime.so\r\n%{_libdir}/collectd/users.so\r\n%{_libdir}/collectd/uuid.so\r\n%{_libdir}/collectd/vmem.so\r\n%{_libdir}/collectd/vserver.so\r\n%{_libdir}/collectd/wireless.so\r\n%{_libdir}/collectd/write_graphite.so\r\n%{_libdir}/collectd/write_http.so\r\n\r\n%{_datadir}/collectd/types.db\r\n\r\n%{_libdir}/libcollectdclient.so\r\n%{_libdir}/libcollectdclient.so.1\r\n%{_libdir}/libcollectdclient.so.1.0.0\r\n%{_libdir}/pkgconfig/libcollectdclient.pc\r\n%{_includedir}/collectd/client.h\r\n%{_includedir}/collectd/lcc_features.h\r\n%{_includedir}/collectd/network.h\r\n%{_includedir}/collectd/network_buffer.h\r\n\r\n%doc AUTHORS ChangeLog COPYING README\r\n%doc %{_mandir}/man1/collectd.1*\r\n%doc %{_mandir}/man1/collectdctl.1*\r\n%doc %{_mandir}/man1/collectd-nagios.1*\r\n%doc %{_mandir}/man1/collectd-tg.1*\r\n%doc %{_mandir}/man1/collectdmon.1*\r\n%doc %{_mandir}/man5/collectd.conf.5*\r\n%doc %{_mandir}/man5/collectd-exec.5*\r\n%doc %{_mandir}/man5/collectd-python.5*\r\n%doc %{_mandir}/man5/collectd-threshold.5*\r\n%doc %{_mandir}/man5/collectd-unixsock.5*\r\n%doc %{_mandir}/man5/types.db.5*\r\n\r\n%files apache\r\n%{_libdir}/collectd/apache.so\r\n#%config(noreplace) %{_sysconfdir}/collectd.d/apache.conf\r\n\r\n%files ascent\r\n%{_libdir}/collectd/ascent.so\r\n\r\n%files bind\r\n%{_libdir}/collectd/bind.so\r\n\r\n%files curl\r\n%{_libdir}/collectd/curl.so\r\n\r\n%files curl_json\r\n%{_libdir}/collectd/curl_json.so\r\n\r\n%files curl_xml\r\n%{_libdir}/collectd/curl_xml.so\r\n\r\n%files dbi\r\n%{_libdir}/collectd/dbi.so\r\n\r\n%files dns\r\n%{_libdir}/collectd/dns.so\r\n#%config(noreplace) %{_sysconfdir}/collectd.d/dns.conf\r\n\r\n%files email\r\n%{_libdir}/collectd/email.so\r\n#%config(noreplace) %{_sysconfdir}/collectd.d/email.conf\r\n%doc %{_mandir}/man5/collectd-email.5*\r\n\r\n%files ipvs\r\n%{_libdir}/collectd/ipvs.so\r\n\r\n%files java\r\n%{_libdir}/collectd/java.so\r\n%dir %{_datadir}/collectd/java/\r\n%{_datadir}/collectd/java/collectd-api.jar\r\n%doc %{_mandir}/man5/collectd-java.5*\r\n\r\n%files generic-jmx\r\n%{_datadir}/collectd/java/generic-jmx.jar\r\n\r\n%files gmond\r\n%{_libdir}/collectd/gmond.so\r\n\r\n%files ipmi\r\n%{_libdir}/collectd/ipmi.so\r\n#%config(noreplace) %{_sysconfdir}/collectd.d/ipmi.conf\r\n\r\n%files iptables\r\n%{_libdir}/collectd/iptables.so\r\n\r\n%files lvm\r\n%{_libdir}/collectd/lvm.so\r\n\r\n%if 0%{?fedora} <= 18\r\n%files memcachec\r\n%{_libdir}/collectd/memcachec.so\r\n%endif\r\n\r\n%files mysql\r\n%{_libdir}/collectd/mysql.so\r\n#%config(noreplace) %{_sysconfdir}/collectd.d/mysql.conf\r\n\r\n%files netlink\r\n%{_libdir}/collectd/netlink.so\r\n\r\n%files nginx\r\n%{_libdir}/collectd/nginx.so\r\n#%config(noreplace) %{_sysconfdir}/collectd.d/nginx.conf\r\n\r\n%files notify_desktop\r\n%{_libdir}/collectd/notify_desktop.so\r\n\r\n%files notify_email\r\n%{_libdir}/collectd/notify_email.so\r\n\r\n%ifnarch ppc ppc64 sparc sparc64\r\n%files sensors\r\n%{_libdir}/collectd/sensors.so\r\n#%config(noreplace) %{_sysconfdir}/collectd.d/sensors.conf\r\n%endif\r\n\r\n%files snmp\r\n%{_libdir}/collectd/snmp.so\r\n#%config(noreplace) %{_sysconfdir}/collectd.d/snmp.conf\r\n%doc %{_mandir}/man5/collectd-snmp.5*\r\n\r\n%files -n perl-Collectd\r\n%doc perl-examples/*\r\n%{_libdir}/collectd/perl.so\r\n%{perl_vendorlib}/Collectd.pm\r\n%{perl_vendorlib}/Collectd/\r\n#%config(noreplace) %{_sysconfdir}/collectd.d/perl.conf\r\n%doc %{_mandir}/man5/collectd-perl.5*\r\n%doc %{_mandir}/man3/Collectd::Unixsock.3pm*\r\n\r\n%files postgresql\r\n%{_libdir}/collectd/postgresql.so\r\n#%config(noreplace) %{_sysconfdir}/collectd.d/postgresql.conf\r\n%{_datadir}/collectd/postgresql_default.conf\r\n\r\n%files rrdtool\r\n%{_libdir}/collectd/rrdtool.so\r\n#%config(noreplace) %{_sysconfdir}/collectd.d/rrdtool.conf\r\n\r\n%ifnarch ppc ppc64 sparc sparc64\r\n%files virt\r\n%{_libdir}/collectd/libvirt.so\r\n#%config(noreplace) %{_sysconfdir}/collectd.d/libvirt.conf\r\n%endif\r\n\r\n%changelog\r\n* Thu Jul 07 2013 Joshua B. Bussdieker <jbussdieker@gmail.com> - 5.4.0-1\r\n- Initial build\r\n</code>\r\n</div>\r\n\r\n<div class="well">\r\n<h2 id="collectd.service">/etc/init.d/collectd</h2>\r\n<code>\r\n#!/bin/bash\r\n#\r\n# collectd    Startup script for the Collectd statistics gathering daemon\r\n# chkconfig: - 86 15\r\n# description: Collectd is a statistics gathering daemon used to collect \\\r\n#   system information ie. cpu, memory, disk, network\r\n# processname: collectd\r\n# config: /etc/collectd.conf\r\n# config: /etc/sysconfig/collectd\r\n# pidfile: /var/run/collectd.pid\r\n\r\n# Source function library.\r\n. /etc/init.d/functions\r\n\r\nRETVAL=0\r\nARGS=""\r\nprog="collectdmon"\r\nCONFIG=/etc/collectd/collectd.conf\r\nCOLLECTD=/usr/sbin/collectd\r\nCOLLECTDMONPID=/var/run/collectdmon.pid\r\n\r\nif [ -r /etc/default/$prog ]; then\r\n\t. /etc/default/$prog\r\nfi\r\n\r\nstart () {\r\n\techo -n $"Starting collectd: "\r\n\tif [ -r "$CONFIG" ]\r\n\tthen\r\n\t\tdaemon $prog -P $COLLECTDMONPID -c $COLLECTD -- -C "$CONFIG"\r\n\t\tRETVAL=$?\r\n\t\techo\r\n\t\t[ $RETVAL -eq 0 ] && touch /var/lock/subsys/$prog\r\n\tfi\r\n}\r\nstop () {\r\n\techo -n $"Stopping collectd: "\r\n\tkillproc $prog\r\n\tRETVAL=$?\r\n\techo\r\n\t[ $RETVAL -eq 0 ] && rm -f /var/lock/subsys/$prog\r\n}\r\n# See how we were called.\r\ncase "$1" in\r\n  start)\r\n\tstart\r\n\t;;\r\n  stop)\r\n\tstop\r\n\t;;\r\n  status)\r\n\tstatus $prog\r\n\t;;\r\n  restart|reload)\r\n\tstop\r\n\tstart\r\n\t;;\r\n  condrestart)\r\n\t[ -f /var/lock/subsys/$prog ] && restart || :\r\n\t;;\r\n  *)\r\n\techo $"Usage: $0 {start|stop|status|restart|reload|condrestart}"\r\n\texit 1\r\nesac\r\n\r\nexit $?\r\n\r\n# vim:syntax=sh\r\n</code>\r\n</div>	2013-11-06 23:52:23.848273	2013-11-07 00:01:16.878757
27	25 - Virtual Machine to AWS EC2	<code lang="bash">\r\novftool \\\r\n  github-enterprise-11.10.312-x86-64.ova \\\r\n  github-enterprise-11.10.312-x86-64.ovf\r\nec2-import-instance \\\r\n  -C [cert_file.pem] \\\r\n  -K [pk_file.pem] \\\r\n  -b [bucket_name] \\\r\n  -f VMDK \\\r\n  -o [access_key_id] \\\r\n  -w [secret_access_key] \\\r\n  -f VMDK github-enterprise-11.10.312-x86-64-disk1.vmdk\r\n</code>	2013-07-11 00:55:40.752598	2013-07-11 01:00:06.593324
\.


--
-- Name: tutorials_id_seq; Type: SEQUENCE SET; Schema: public; Owner: hwttebiccfumlp
--

SELECT pg_catalog.setval('tutorials_id_seq', 36, true);


--
-- Data for Name: users; Type: TABLE DATA; Schema: public; Owner: hwttebiccfumlp
--

COPY users (id, email, encrypted_password, reset_password_token, reset_password_sent_at, remember_created_at, sign_in_count, current_sign_in_at, last_sign_in_at, current_sign_in_ip, last_sign_in_ip, created_at, updated_at) FROM stdin;
1	jbussdieker@gmail.com	$2a$10$7ifkKPCftg1HO7EeqVpL9uu/YA2ycm3o4kkBcSJPT7OQYcimUV1pK	\N	\N	\N	29	2014-03-05 23:23:42.542384	2014-01-29 02:50:02.859069	70.35.40.250	70.35.40.250	2013-03-03 21:11:17.843186	2014-03-05 23:23:42.556318
\.


--
-- Name: users_id_seq; Type: SEQUENCE SET; Schema: public; Owner: hwttebiccfumlp
--

SELECT pg_catalog.setval('users_id_seq', 1, true);


--
-- Name: tutorials_pkey; Type: CONSTRAINT; Schema: public; Owner: hwttebiccfumlp; Tablespace: 
--

ALTER TABLE ONLY tutorials
    ADD CONSTRAINT tutorials_pkey PRIMARY KEY (id);


--
-- Name: users_pkey; Type: CONSTRAINT; Schema: public; Owner: hwttebiccfumlp; Tablespace: 
--

ALTER TABLE ONLY users
    ADD CONSTRAINT users_pkey PRIMARY KEY (id);


--
-- Name: index_users_on_email; Type: INDEX; Schema: public; Owner: hwttebiccfumlp; Tablespace: 
--

CREATE UNIQUE INDEX index_users_on_email ON users USING btree (email);


--
-- Name: index_users_on_reset_password_token; Type: INDEX; Schema: public; Owner: hwttebiccfumlp; Tablespace: 
--

CREATE UNIQUE INDEX index_users_on_reset_password_token ON users USING btree (reset_password_token);


--
-- Name: unique_schema_migrations; Type: INDEX; Schema: public; Owner: hwttebiccfumlp; Tablespace: 
--

CREATE UNIQUE INDEX unique_schema_migrations ON schema_migrations USING btree (version);


--
-- Name: public; Type: ACL; Schema: -; Owner: hwttebiccfumlp
--

REVOKE ALL ON SCHEMA public FROM PUBLIC;
REVOKE ALL ON SCHEMA public FROM hwttebiccfumlp;
GRANT ALL ON SCHEMA public TO hwttebiccfumlp;
GRANT ALL ON SCHEMA public TO PUBLIC;


--
-- PostgreSQL database dump complete
--

